name: ğŸ¤– Automated Job Scraper

on:
  # Run every 30 minutes
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  
  # Allow manual triggering from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: scraper/package-lock.json

      - name: ğŸ“¦ Install dependencies
        run: |
          cd scraper
          npm ci

      - name: ğŸ­ Install Playwright browsers
        run: |
          cd scraper
          npx playwright install --with-deps chromium

      - name: ğŸ” Run job scrapers
        env:
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          cd scraper
          node index.js

      - name: âœ… Scraping completed
        run: echo "Job scraping completed successfully!"
