name: ü§ñ Automated Job Scraper

on:
  # Run every 10 minutes
  schedule:
    - cron: '*/10 * * * *'  # Every 10 minutes
  
  # Allow manual triggering from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üü¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: scraper/package-lock.json

      - name: üì¶ Install dependencies
        run: |
          cd scraper
          npm ci

      - name: üé≠ Install Playwright browsers
        run: |
          cd scraper
          npx playwright install --with-deps chromium

      - name: üîç Run job scrapers
        env:
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          Z_AI_API_KEY: ${{ secrets.Z_AI_API_KEY }}
          FLOWITH_API_KEY: ${{ secrets.FLOWITH_API_KEY }}
        run: |
          cd scraper
          node index.js

      - name: ‚úÖ Scraping completed
        run: echo "Job scraping completed successfully!"
